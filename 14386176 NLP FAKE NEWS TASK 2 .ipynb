{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7ef6b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, SpatialDropout1D, Conv1D, MaxPooling1D ,SimpleRNN,  GlobalMaxPooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0c10127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('Constraint_Train (1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27b2ab30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "df['label'] = df['label'].map({'real': 1, 'fake': 0})\n",
    "df['tweet'] = df['tweet'].apply(lambda x: x.lower())\n",
    "df['tweet'] = df['tweet'].apply(lambda x: re.sub('\\[.*?\\]', '', x))\n",
    "df['tweet'] = df['tweet'].apply(lambda x: re.sub(\"\\\\W\", \" \", x))\n",
    "df['tweet'] = df['tweet'].apply(lambda x: re.sub('http?://\\S+|www.\\.\\S+', '', x))\n",
    "df['tweet'] = df['tweet'].apply(lambda x: re.sub('<.*?>+', '', x))\n",
    "df['tweet'] = df['tweet'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x))\n",
    "df['tweet'] = df['tweet'].apply(lambda x: re.sub('\\n', '', x))\n",
    "df['tweet'] = df['tweet'].apply(lambda x: re.sub('\\w*\\d\\w*', '', x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63d7b7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def wordopt(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub('\\[.*?\\]', '', tweet)\n",
    "    tweet = re.sub(\"\\\\W\", \" \", tweet)\n",
    "    tweet = re.sub('http?://\\S+|www.\\.\\S+', '', tweet)\n",
    "    tweet = re.sub('<.*?>+', '', tweet)\n",
    "    tweet = re.sub('[%s]' % re.escape(string.punctuation), '', tweet)\n",
    "    tweet = re.sub('\\n', '', tweet)\n",
    "    tweet = re.sub('\\w*\\d\\w*', '', tweet)\n",
    "    return tweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50062245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['tweet'], df['label'], test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7a3268a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "max_words = 5000\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "x_train_seq = tokenizer.texts_to_sequences(x_train)\n",
    "x_test_seq = tokenizer.texts_to_sequences(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7063baf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences for uniform length\n",
    "max_len = 100  # You can adjust this based on your data and model complexity\n",
    "x_train_pad = pad_sequences(x_train_seq, maxlen=max_len)\n",
    "x_test_pad = pad_sequences(x_test_seq, maxlen=max_len)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da473de8",
   "metadata": {},
   "source": [
    "# LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2215ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build LSTM model\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(Embedding(max_words, 128, input_length=max_len))\n",
    "model_lstm.add(SpatialDropout1D(0.2))\n",
    "model_lstm.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model_lstm.add(Dense(1, activation='sigmoid'))\n",
    "model_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ccd7e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "161/161 [==============================] - 46s 225ms/step - loss: 0.3479 - accuracy: 0.8423 - val_loss: 0.2045 - val_accuracy: 0.9182\n",
      "Epoch 2/5\n",
      "161/161 [==============================] - 46s 283ms/step - loss: 0.1116 - accuracy: 0.9591 - val_loss: 0.1984 - val_accuracy: 0.9190\n",
      "Epoch 3/5\n",
      "161/161 [==============================] - 44s 274ms/step - loss: 0.0680 - accuracy: 0.9778 - val_loss: 0.2438 - val_accuracy: 0.8956\n",
      "Epoch 4/5\n",
      "161/161 [==============================] - 38s 233ms/step - loss: 0.0344 - accuracy: 0.9901 - val_loss: 0.2721 - val_accuracy: 0.9268\n",
      "Epoch 5/5\n",
      "161/161 [==============================] - 34s 214ms/step - loss: 0.0263 - accuracy: 0.9910 - val_loss: 0.3457 - val_accuracy: 0.8707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x295eac04690>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the LSTM model\n",
    "model_lstm.fit(x_train_pad, y_train, epochs=5, batch_size=32, validation_data=(x_test_pad, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5eb493f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 2s 35ms/step - loss: 0.3457 - accuracy: 0.8707\n",
      "Test Accuracy: 0.8707165122032166\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_lstm.evaluate(x_test_pad, y_test)\n",
    "print(f'Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1cab94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 2s 38ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_lstm.predict(x_test_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e817a216",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ce1709a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85cdcf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 34ms/step\n"
     ]
    }
   ],
   "source": [
    "lstm_predictions = model_lstm.predict(x_test_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00484d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.76      0.85       596\n",
      "           1       0.82      0.96      0.89       688\n",
      "\n",
      "    accuracy                           0.87      1284\n",
      "   macro avg       0.89      0.86      0.87      1284\n",
      "weighted avg       0.88      0.87      0.87      1284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64dbe4e",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26432d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:6642: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ... (previous code for data preprocessing, LSTM model, and common functions)\n",
    "\n",
    "# Build CNN model\n",
    "model_cnn = Sequential()\n",
    "model_cnn.add(Embedding(max_words, 128, input_length=max_len))\n",
    "model_cnn.add(Conv1D(64, kernel_size=3, activation='relu'))\n",
    "model_cnn.add(MaxPooling1D(pool_size=2))\n",
    "model_cnn.add(LSTM(100))\n",
    "model_cnn.add(Dense(1, activation='sigmoid'))\n",
    "model_cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98817573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "161/161 [==============================] - 20s 86ms/step - loss: 0.3234 - accuracy: 0.8472 - val_loss: 0.2136 - val_accuracy: 0.9065\n",
      "Epoch 2/5\n",
      "161/161 [==============================] - 12s 75ms/step - loss: 0.0951 - accuracy: 0.9665 - val_loss: 0.2251 - val_accuracy: 0.9221\n",
      "Epoch 3/5\n",
      "161/161 [==============================] - 12s 75ms/step - loss: 0.0359 - accuracy: 0.9893 - val_loss: 0.2775 - val_accuracy: 0.9143\n",
      "Epoch 4/5\n",
      "161/161 [==============================] - 12s 75ms/step - loss: 0.0151 - accuracy: 0.9949 - val_loss: 0.3469 - val_accuracy: 0.9151\n",
      "Epoch 5/5\n",
      "161/161 [==============================] - 12s 77ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.4060 - val_accuracy: 0.9104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x295f6beead0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the CNN model\n",
    "model_cnn.fit(x_train_pad, y_train, epochs=5, batch_size=32, validation_data=(x_test_pad, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec6447ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 25ms/step - loss: 0.4060 - accuracy: 0.9104\n",
      "Test Accuracy: 0.9104361534118652\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_cnn.evaluate(x_test_pad, y_test)\n",
    "print(f'Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b323711a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 2s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_cnn.predict(x_test_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19984ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42bd804c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da8e27a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "cnn_predictions = model_cnn.predict(x_test_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0cb4a28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91       596\n",
      "           1       0.93      0.90      0.92       688\n",
      "\n",
      "    accuracy                           0.91      1284\n",
      "   macro avg       0.91      0.91      0.91      1284\n",
      "weighted avg       0.91      0.91      0.91      1284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe00549",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c10b2e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnn = Sequential()\n",
    "model_rnn.add(Embedding(max_words, 128, input_length=max_len))\n",
    "model_rnn.add(SimpleRNN(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model_rnn.add(Dense(1, activation='sigmoid'))\n",
    "model_rnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "027dc240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "161/161 [==============================] - 21s 106ms/step - loss: 0.5460 - accuracy: 0.7204 - val_loss: 0.3251 - val_accuracy: 0.8598\n",
      "Epoch 2/5\n",
      "161/161 [==============================] - 16s 101ms/step - loss: 0.2654 - accuracy: 0.8882 - val_loss: 0.5560 - val_accuracy: 0.7858\n",
      "Epoch 3/5\n",
      "161/161 [==============================] - 17s 106ms/step - loss: 0.1573 - accuracy: 0.9385 - val_loss: 0.3770 - val_accuracy: 0.8692\n",
      "Epoch 4/5\n",
      "161/161 [==============================] - 16s 102ms/step - loss: 0.1075 - accuracy: 0.9589 - val_loss: 0.3004 - val_accuracy: 0.9089\n",
      "Epoch 5/5\n",
      "161/161 [==============================] - 17s 103ms/step - loss: 0.0641 - accuracy: 0.9776 - val_loss: 0.4407 - val_accuracy: 0.8933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x295fa48d2d0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rnn.fit(x_train_pad, y_train, epochs=5, batch_size=32, validation_data=(x_test_pad, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "309c0f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 17ms/step - loss: 0.4407 - accuracy: 0.8933\n",
      "RNN Accuracy: 0.8933022022247314\n"
     ]
    }
   ],
   "source": [
    "accuracy_rnn = model_rnn.evaluate(x_test_pad, y_test)\n",
    "print(\"RNN Accuracy:\", accuracy_rnn[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78ea0365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 16ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_rnn.predict(x_test_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d0cd822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0cc13a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d8b7ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 1s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "rnn_predictions = model_rnn.predict(x_test_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "53cb61ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.89       596\n",
      "           1       0.96      0.84      0.89       688\n",
      "\n",
      "    accuracy                           0.89      1284\n",
      "   macro avg       0.90      0.90      0.89      1284\n",
      "weighted avg       0.90      0.89      0.89      1284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc9275c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c491651",
   "metadata": {},
   "source": [
    "# LSTM prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a85f585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the output for a random input\n",
    "def predict_output(model, text):\n",
    "    text = wordopt(text.lower())  # Applying wordopt here\n",
    "    sequence = tokenizer.texts_to_sequences([text])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_len)\n",
    "    prediction = model.predict(padded_sequence)\n",
    "    return prediction[0][0]\n",
    "\n",
    "news = input(\"Enter a news text: \")\n",
    "lstm_prediction = predict_output(model_lstm, news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19873d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_lable(n):\n",
    "    if n == 0:\n",
    "        return \"Fake News\"\n",
    "    elif n == 1:\n",
    "        return \"Not A Fake News\"\n",
    "\n",
    "print(\"\\nLSTM Prediction:\", output_lable(round(lstm_prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1814e255",
   "metadata": {},
   "source": [
    "# CNN prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4862972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the output for a random input\n",
    "def predict_output(model, text):\n",
    "    text = wordopt(text.lower())  # Applying wordopt here\n",
    "    sequence = tokenizer.texts_to_sequences([text])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_len)\n",
    "    prediction = model.predict(padded_sequence)\n",
    "    return prediction[0][0]\n",
    "\n",
    "news = input(\"Enter a news text: \")\n",
    "cnn_prediction = predict_output(model_cnn, news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a2b985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_lable(n):\n",
    "    if n == 0:\n",
    "        return \"Fake News\"\n",
    "    elif n == 1:\n",
    "        return \"Not A Fake News\"\n",
    "\n",
    "print(\"\\nCNN Prediction:\", output_lable(round(cnn_prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2043519e",
   "metadata": {},
   "source": [
    "# RNN prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9a1c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the output for a random input\n",
    "def predict_output(model, text):\n",
    "    text = wordopt(text.lower())  # Applying wordopt here\n",
    "    sequence = tokenizer.texts_to_sequences([text])\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_len)\n",
    "    prediction = model.predict(padded_sequence)\n",
    "    return prediction[0][0]\n",
    "\n",
    "news = input(\"Enter a news text: \")\n",
    "rnn_prediction = predict_output(model_rnn, news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "18ad7ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RNN Prediction: Not A Fake News\n"
     ]
    }
   ],
   "source": [
    "def output_lable(n):\n",
    "    if n == 0:\n",
    "        return \"Fake News\"\n",
    "    elif n == 1:\n",
    "        return \"Not A Fake News\"\n",
    "\n",
    "print(\"\\nRNN Prediction:\", output_lable(round(rnn_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98194034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
